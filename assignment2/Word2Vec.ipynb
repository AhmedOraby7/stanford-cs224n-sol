{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Word2Vec.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cJCs9Sj3XA48","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"fc7bfc8c-957e-4194-c90f-ccf3f5c0a802","executionInfo":{"status":"ok","timestamp":1567832462353,"user_tz":-480,"elapsed":7526,"user":{"displayName":"radream","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdVX7T48nM1swQqTFQB37YCJpipfpOuklEdcRHBQ=s64","userId":"01110408961739688657"}}},"source":["! wget http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip"],"execution_count":1,"outputs":[{"output_type":"stream","text":["--2019-09-07 05:00:56--  http://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip [following]\n","--2019-09-07 05:00:56--  https://nlp.stanford.edu/~socherr/stanfordSentimentTreebank.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6372817 (6.1M) [application/zip]\n","Saving to: ‘stanfordSentimentTreebank.zip’\n","\n","stanfordSentimentTr 100%[===================>]   6.08M  1.90MB/s    in 3.2s    \n","\n","2019-09-07 05:01:00 (1.90 MB/s) - ‘stanfordSentimentTreebank.zip’ saved [6372817/6372817]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ApFHruMQXR1J","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"a8246c05-adf7-4300-cd80-fc656a2d5044","executionInfo":{"status":"ok","timestamp":1567832472601,"user_tz":-480,"elapsed":3292,"user":{"displayName":"radream","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdVX7T48nM1swQqTFQB37YCJpipfpOuklEdcRHBQ=s64","userId":"01110408961739688657"}}},"source":["! unzip stanfordSentimentTreebank.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Archive:  stanfordSentimentTreebank.zip\n","   creating: stanfordSentimentTreebank/\n","  inflating: stanfordSentimentTreebank/datasetSentences.txt  \n","   creating: __MACOSX/\n","   creating: __MACOSX/stanfordSentimentTreebank/\n","  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSentences.txt  \n","  inflating: stanfordSentimentTreebank/datasetSplit.txt  \n","  inflating: __MACOSX/stanfordSentimentTreebank/._datasetSplit.txt  \n","  inflating: stanfordSentimentTreebank/dictionary.txt  \n","  inflating: __MACOSX/stanfordSentimentTreebank/._dictionary.txt  \n","  inflating: stanfordSentimentTreebank/original_rt_snippets.txt  \n","  inflating: __MACOSX/stanfordSentimentTreebank/._original_rt_snippets.txt  \n","  inflating: stanfordSentimentTreebank/README.txt  \n","  inflating: __MACOSX/stanfordSentimentTreebank/._README.txt  \n","  inflating: stanfordSentimentTreebank/sentiment_labels.txt  \n","  inflating: __MACOSX/stanfordSentimentTreebank/._sentiment_labels.txt  \n","  inflating: stanfordSentimentTreebank/SOStr.txt  \n","  inflating: stanfordSentimentTreebank/STree.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bCqNX5ieXZRY","colab_type":"code","colab":{}},"source":["! rm stanfordSentimentTreebank.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qE3NOEURWx1E","colab_type":"code","colab":{}},"source":["import os, pickle, glob, random, time\n","import os.path as op\n","\n","import cupy as np\n","import matplotlib.pyplot as plt\n","\n","%reload_ext autoreload\n","%autoreload 0\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"InwAgbbaYgsE","colab_type":"code","colab":{}},"source":["class StanfordSentiment:\n","    def __init__(self, path=None, tablesize = 1000000):\n","        if not path:\n","            path = \"./stanfordSentimentTreebank\"\n","\n","        self.path = path\n","        self.tablesize = tablesize\n","\n","    def tokens(self):\n","        if hasattr(self, \"_tokens\") and self._tokens:\n","            return self._tokens\n","\n","        tokens = dict()\n","        tokenfreq = dict()\n","        wordcount = 0\n","        revtokens = []\n","        idx = 0\n","\n","        for sentence in self.sentences():\n","            for w in sentence:\n","                wordcount += 1\n","                if not w in tokens:\n","                    tokens[w] = idx\n","                    revtokens += [w]\n","                    tokenfreq[w] = 1\n","                    idx += 1\n","                else:\n","                    tokenfreq[w] += 1\n","\n","        tokens[\"UNK\"] = idx\n","        revtokens += [\"UNK\"]\n","        tokenfreq[\"UNK\"] = 1\n","        wordcount += 1\n","\n","        self._tokens = tokens\n","        self._tokenfreq = tokenfreq\n","        self._wordcount = wordcount\n","        self._revtokens = revtokens\n","        return self._tokens\n","\n","    def sentences(self):\n","        if hasattr(self, \"_sentences\") and self._sentences:\n","            return self._sentences\n","\n","        sentences = []\n","        with open(self.path + \"/datasetSentences.txt\", \"r\") as f:\n","            first = True\n","            for line in f:\n","                if first:\n","                    first = False\n","                    continue\n","\n","                splitted = line.strip().split()[1:]\n","                # Deal with some peculiar encoding issues with this file\n","                sentences += [[w.lower() for w in splitted]]\n","\n","        self._sentences = sentences\n","        self._sentlengths = np.array([len(s) for s in sentences])\n","        self._cumsentlen = np.cumsum(self._sentlengths)\n","\n","        return self._sentences\n","\n","    def numSentences(self):\n","        if hasattr(self, \"_numSentences\") and self._numSentences:\n","            return self._numSentences\n","        else:\n","            self._numSentences = len(self.sentences())\n","            return self._numSentences\n","\n","    def allSentences(self):\n","        if hasattr(self, \"_allsentences\") and self._allsentences:\n","            return self._allsentences\n","\n","        sentences = self.sentences()\n","        rejectProb = self.rejectProb()\n","        tokens = self.tokens()\n","        allsentences = [[w for w in s\n","            if 0 >= rejectProb[tokens[w]] or random.random() >= rejectProb[tokens[w]]]\n","            for s in sentences * 30]\n","\n","        allsentences = [s for s in allsentences if len(s) > 1]\n","\n","        self._allsentences = allsentences\n","\n","        return self._allsentences\n","\n","    def getRandomContext(self, C=5):\n","        allsent = self.allSentences()\n","        sentID = random.randint(0, len(allsent) - 1)\n","        sent = allsent[sentID]\n","        wordID = random.randint(0, len(sent) - 1)\n","\n","        context = sent[max(0, wordID - C):wordID]\n","        if wordID+1 < len(sent):\n","            context += sent[wordID+1:min(len(sent), wordID + C + 1)]\n","\n","        centerword = sent[wordID]\n","        context = [w for w in context if w != centerword]\n","\n","        if len(context) > 0:\n","            return centerword, context\n","        else:\n","            return self.getRandomContext(C)\n","\n","    def sent_labels(self):\n","        if hasattr(self, \"_sent_labels\") and self._sent_labels:\n","            return self._sent_labels\n","\n","        dictionary = dict()\n","        phrases = 0\n","        with open(self.path + \"/dictionary.txt\", \"r\") as f:\n","            for line in f:\n","                line = line.strip()\n","                if not line: continue\n","                splitted = line.split(\"|\")\n","                dictionary[splitted[0].lower()] = int(splitted[1])\n","                phrases += 1\n","\n","        labels = [0.0] * phrases\n","        with open(self.path + \"/sentiment_labels.txt\", \"r\") as f:\n","            first = True\n","            for line in f:\n","                if first:\n","                    first = False\n","                    continue\n","\n","                line = line.strip()\n","                if not line: continue\n","                splitted = line.split(\"|\")\n","                labels[int(splitted[0])] = float(splitted[1])\n","\n","        sent_labels = [0.0] * self.numSentences()\n","        sentences = self.sentences()\n","        for i in range(self.numSentences()):\n","            sentence = sentences[i]\n","            full_sent = \" \".join(sentence).replace('-lrb-', '(').replace('-rrb-', ')')\n","            sent_labels[i] = labels[dictionary[full_sent]]\n","\n","        self._sent_labels = sent_labels\n","        return self._sent_labels\n","\n","    def dataset_split(self):\n","        if hasattr(self, \"_split\") and self._split:\n","            return self._split\n","\n","        split = [[] for i in range(3)]\n","        with open(self.path + \"/datasetSplit.txt\", \"r\") as f:\n","            first = True\n","            for line in f:\n","                if first:\n","                    first = False\n","                    continue\n","\n","                splitted = line.strip().split(\",\")\n","                split[int(splitted[1]) - 1] += [int(splitted[0]) - 1]\n","\n","        self._split = split\n","        return self._split\n","\n","    def getRandomTrainSentence(self):\n","        split = self.dataset_split()\n","        sentId = split[0][random.randint(0, len(split[0]) - 1)]\n","        return self.sentences()[sentId], self.categorify(self.sent_labels()[sentId])\n","\n","    def categorify(self, label):\n","        if label <= 0.2:\n","            return 0\n","        elif label <= 0.4:\n","            return 1\n","        elif label <= 0.6:\n","            return 2\n","        elif label <= 0.8:\n","            return 3\n","        else:\n","            return 4\n","\n","    def getDevSentences(self):\n","        return self.getSplitSentences(2)\n","\n","    def getTestSentences(self):\n","        return self.getSplitSentences(1)\n","\n","    def getTrainSentences(self):\n","        return self.getSplitSentences(0)\n","\n","    def getSplitSentences(self, split=0):\n","        ds_split = self.dataset_split()\n","        return [(self.sentences()[i], self.categorify(self.sent_labels()[i])) for i in ds_split[split]]\n","\n","    def sampleTable(self):\n","        if hasattr(self, '_sampleTable') and self._sampleTable is not None:\n","            return self._sampleTable\n","\n","        nTokens = len(self.tokens())\n","        samplingFreq = np.zeros((nTokens,))\n","        self.allSentences()\n","        i = 0\n","        for w in range(nTokens):\n","            w = self._revtokens[i]\n","            if w in self._tokenfreq:\n","                freq = 1.0 * self._tokenfreq[w]\n","                # Reweigh\n","                freq = freq ** 0.75\n","            else:\n","                freq = 0.0\n","            samplingFreq[i] = freq\n","            i += 1\n","\n","        samplingFreq /= np.sum(samplingFreq)\n","        samplingFreq = np.cumsum(samplingFreq) * self.tablesize\n","\n","        self._sampleTable = [0] * self.tablesize\n","\n","        j = 0\n","        for i in range(self.tablesize):\n","            while i > samplingFreq[j]:\n","                j += 1\n","            self._sampleTable[i] = j\n","\n","        return self._sampleTable\n","\n","    def rejectProb(self):\n","        if hasattr(self, '_rejectProb') and self._rejectProb is not None:\n","            return self._rejectProb\n","\n","        threshold = 1e-5 * self._wordcount\n","\n","        nTokens = len(self.tokens())\n","        rejectProb = np.zeros((nTokens,))\n","        for i in range(nTokens):\n","            w = self._revtokens[i]\n","            freq = 1.0 * self._tokenfreq[w]\n","            # Reweigh\n","            rejectProb[i] = max(0, 1 - np.sqrt(threshold / freq))\n","\n","        self._rejectProb = rejectProb\n","        return self._rejectProb\n","\n","    def sampleTokenIdx(self):\n","        return self.sampleTable()[random.randint(0, self.tablesize - 1)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NMZ1TiEUYUmL","colab_type":"code","colab":{}},"source":["def normalizeRows(x):\n","    \"\"\" Row normalization function\n","\n","    Implement a function that normalizes each row of a matrix to have\n","    unit length.\n","    \"\"\"\n","    N = x.shape[0]\n","    x /= np.sqrt(np.sum(x**2, axis=1)).reshape((N,1)) + 1e-30\n","    return x\n","\n","def softmax(x):\n","    \"\"\"Compute the softmax function for each row of the input x.\n","    It is crucial that this function is optimized for speed because\n","    it will be used frequently in later code. \n","\n","    Arguments:\n","    x -- A D dimensional vector or N x D dimensional numpy matrix.\n","    Return:\n","    x -- You are allowed to modify x in-place\n","    \"\"\"\n","    orig_shape = x.shape\n","\n","    if len(x.shape) > 1:\n","        # Matrix\n","        tmp = np.max(x, axis=1)\n","        x -= tmp.reshape((x.shape[0], 1))\n","        x = np.exp(x)\n","        tmp = np.sum(x, axis=1)\n","        x /= tmp.reshape((x.shape[0], 1))\n","    else:\n","        # Vector\n","        tmp = np.max(x)\n","        x -= tmp\n","        x = np.exp(x)\n","        tmp = np.sum(x)\n","        x /= tmp\n","\n","    assert x.shape == orig_shape\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5I-ldQkbZIyO","colab_type":"code","colab":{}},"source":["SAVE_PARAMS_EVERY = 5000\n","\n","def load_saved_params():\n","    \"\"\"\n","    A helper function that loads previously saved parameters and resets\n","    iteration start.\n","    \"\"\"\n","    st = 0\n","    for f in glob.glob(\"saved_params_*.npy\"):\n","        iter = int(op.splitext(op.basename(f))[0].split(\"_\")[2])\n","        if (iter > st):\n","            st = iter\n","\n","    if st > 0:\n","        params_file = \"saved_params_%d.npy\" % st\n","        state_file = \"saved_state_%d.pickle\" % st\n","        params = np.load(params_file)\n","        with open(state_file, \"rb\") as f:\n","            state = pickle.load(f)\n","        return st, params, state\n","    else:\n","        return st, None, None\n","\n","\n","def save_params(iter, params):\n","    params_file = \"saved_params_%d.npy\" % iter\n","    np.save(params_file, params)\n","    with open(\"saved_state_%d.pickle\" % iter, \"wb\") as f:\n","        pickle.dump(random.getstate(), f)\n","\n","\n","def sgd(f, x0, step, iterations, postprocessing=None, useSaved=False,\n","        PRINT_EVERY=10):\n","    \"\"\" Stochastic Gradient Descent\n","\n","    Implement the stochastic gradient descent method in this function.\n","\n","    Arguments:\n","    f -- the function to optimize, it should take a single\n","         argument and yield two outputs, a loss and the gradient\n","         with respect to the arguments\n","    x0 -- the initial point to start SGD from\n","    step -- the step size for SGD\n","    iterations -- total iterations to run SGD for\n","    postprocessing -- postprocessing function for the parameters\n","                      if necessary. In the case of word2vec we will need to\n","                      normalize the word vectors to have unit length.\n","    PRINT_EVERY -- specifies how many iterations to output loss\n","\n","    Return:\n","    x -- the parameter value after SGD finishes\n","    \"\"\"\n","\n","    # Anneal learning rate every several iterations\n","    ANNEAL_EVERY = 20000\n","\n","    if useSaved:\n","        start_iter, oldx, state = load_saved_params()\n","        if start_iter > 0:\n","            x0 = oldx\n","            step *= 0.5 ** (start_iter / ANNEAL_EVERY)\n","\n","        if state:\n","            random.setstate(state)\n","    else:\n","        start_iter = 0\n","\n","    x = x0\n","\n","    if not postprocessing:\n","        postprocessing = lambda x: x\n","\n","    exploss = None\n","\n","    for iter in range(start_iter + 1, iterations + 1):\n","        # You might want to print the progress every few iterations.\n","\n","        loss = None\n","        ### YOUR CODE HERE\n","        loss, grad = f(x)\n","        x -= step * grad\n","        ### END YOUR CODE\n","\n","        x = postprocessing(x)\n","        if iter % PRINT_EVERY == 0 or iter == 100:\n","            if not exploss:\n","                exploss = loss\n","            else:\n","                exploss = .95 * exploss + .05 * loss\n","            print(\"iter %d: %f\" % (iter, exploss))\n","\n","        if iter % SAVE_PARAMS_EVERY == 0 and useSaved:\n","            save_params(iter, x)\n","\n","        if iter % ANNEAL_EVERY == 0:\n","            step *= 0.5\n","\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X7XHIi8XZJRl","colab_type":"code","colab":{}},"source":["def sigmoid(x):\n","    \"\"\"\n","    Compute the sigmoid function for the input here.\n","    Arguments:\n","    x -- A scalar or numpy array.\n","    Return:\n","    s -- sigmoid(x)\n","    \"\"\"\n","\n","    ### YOUR CODE HERE\n","    s = 1 / (1 + np.exp(-x))\n","\n","    ### END YOUR CODE\n","\n","    return s\n","\n","\n","def naiveSoftmaxLossAndGradient(\n","    centerWordVec,\n","    outsideWordIdx,\n","    outsideVectors,\n","    dataset\n","):\n","    \"\"\" Naive Softmax loss & gradient function for word2vec models\n","\n","    Implement the naive softmax loss and gradients between a center word's\n","    embedding and an outside word's embedding. This will be the building block\n","    for our word2vec models.\n","\n","    Arguments:\n","    centerWordVec -- numpy ndarray, center word's embedding\n","                    (v_c in the pdf handout)\n","    outsideWordIdx -- integer, the index of the outside word\n","                    (o of u_o in the pdf handout)\n","    outsideVectors -- outside vectors (rows of matrix) for all words in vocab\n","                      (U in the pdf handout)\n","    dataset -- needed for negative sampling, unused here.\n","\n","    Return:\n","    loss -- naive softmax loss\n","    gradCenterVec -- the gradient with respect to the center word vector\n","                     (dJ / dv_c in the pdf handout)\n","    gradOutsideVecs -- the gradient with respect to all the outside word vectors\n","                    (dJ / dU)\n","    \"\"\"\n","\n","    ### YOUR CODE HERE\n","\n","    ### Please use the provided softmax function (imported earlier in this file)\n","    ### This numerically stable implementation helps you avoid issues pertaining\n","    ### to integer overflow.\n","\n","    out_prob = softmax(outsideVectors.dot(centerWordVec))  # (V,) from (V, M) dot (M,)\n","    loss = -np.log(out_prob[outsideWordIdx])\n","\n","    out_prob[outsideWordIdx] -= 1  # dJ / d(softmax)\n","    gradCenterVec = outsideVectors.T.dot(out_prob)  # (M,) = (M, V) dot (V,)\n","    gradOutsideVecs = out_prob[:, np.newaxis].dot(centerWordVec[np.newaxis, :])  # (V, M) = (V, 1) dot (1, M)\n","\n","    ### END YOUR CODE\n","\n","    return loss, gradCenterVec, gradOutsideVecs\n","\n","\n","def getNegativeSamples(outsideWordIdx, dataset, K):\n","    \"\"\" Samples K indexes which are not the outsideWordIdx \"\"\"\n","\n","    negSampleWordIndices = [None] * K\n","    for k in range(K):\n","        newidx = dataset.sampleTokenIdx()\n","        while newidx == outsideWordIdx:\n","            newidx = dataset.sampleTokenIdx()\n","        negSampleWordIndices[k] = newidx\n","    return negSampleWordIndices\n","\n","\n","def negSamplingLossAndGradient(\n","    centerWordVec,\n","    outsideWordIdx,\n","    outsideVectors,\n","    dataset,\n","    K=10\n","):\n","    \"\"\" Negative sampling loss function for word2vec models\n","\n","    Implement the negative sampling loss and gradients for a centerWordVec\n","    and a outsideWordIdx word vector as a building block for word2vec\n","    models. K is the number of negative samples to take.\n","\n","    Note: The same word may be negatively sampled multiple times. For\n","    example if an outside word is sampled twice, you shall have to\n","    double count the gradient with respect to this word. Thrice if\n","    it was sampled three times, and so forth.\n","\n","    Arguments/Return Specifications: same as naiveSoftmaxLossAndGradient\n","    \"\"\"\n","\n","    # Negative sampling of words is done for you. Do not modify this if you\n","    # wish to match the autograder and receive points!\n","    random.seed(42)\n","    negSampleWordIndices = getNegativeSamples(outsideWordIdx, dataset, K)\n","    indices = [outsideWordIdx] + negSampleWordIndices\n","\n","    ### YOUR CODE HERE\n","    gradCenterVec = np.zeros(centerWordVec.shape, dtype=np.float32)\n","    gradOutsideVecs = np.zeros(outsideVectors.shape, dtype=np.float32)\n","    out_probs = np.zeros(K+1, dtype=np.float32)\n","    \n","    ### Please use your implementation of sigmoid in here.\n","    out_probs[0] += sigmoid(np.dot(outsideVectors[indices[0]], centerWordVec))\n","    out_probs[1:] += sigmoid(-np.dot(outsideVectors[indices[1:]], centerWordVec))\n","    loss = -np.log(out_probs).sum()\n","\n","    out_probs[0] -= 1.0\n","    out_probs[1:] = 1.0 - out_probs[1:]\n","    gradCenterVec += out_probs.dot(outsideVectors[indices])  # (M,) = (K+1,) dot (K+1, M)\n","    for k, idx in enumerate(indices):\n","        gradOutsideVecs[idx] += out_probs[k] * centerWordVec\n","\n","    # My finding:\n","    #\n","    # Cannot used the code in the line below, because there may be repeated\n","    # elements in indices. The gradient won't be accumulated for the repeated\n","    # ones, causing wrong results in gradOutsideVecs\n","\n","    # gradOutsideVecs[indices] += out_probs[:, None].dot(centerWordVec[None, :])  # (K+1, M) = (K+1, 1) dot (1, M)\n","\n","    ### END YOUR CODE\n","\n","    return loss, gradCenterVec, gradOutsideVecs\n","\n","\n","def skipgram(currentCenterWord, windowSize, outsideWords, word2Ind,\n","             centerWordVectors, outsideVectors, dataset,\n","             word2vecLossAndGradient=naiveSoftmaxLossAndGradient):\n","    \"\"\" Skip-gram model in word2vec\n","\n","    Implement the skip-gram model in this function.\n","\n","    Arguments:\n","    currentCenterWord -- a string of the current center word\n","    windowSize -- integer, context window size\n","    outsideWords -- list of no more than 2*windowSize strings, the outside words\n","    word2Ind -- a dictionary that maps words to their indices in\n","              the word vector list\n","    centerWordVectors -- center word vectors (as rows) for all words in vocab\n","                        (V in pdf handout)\n","    outsideVectors -- outside word vectors (as rows) for all words in vocab\n","                    (U in pdf handout)\n","    word2vecLossAndGradient -- the loss and gradient function for\n","                               a prediction vector given the outsideWordIdx\n","                               word vectors, could be one of the two\n","                               loss functions you implemented above.\n","\n","    Return:\n","    loss -- the loss function value for the skip-gram model\n","            (J in the pdf handout)\n","    gradCenterVecs -- the gradient with respect to the center word vectors\n","            (dJ / dV in the pdf handout)\n","    gradOutsideVectors -- the gradient with respect to the outside word vectors\n","                        (dJ / dU in the pdf handout)\n","    \"\"\"\n","\n","    loss = 0.0\n","    gradCenterVecs = np.zeros(centerWordVectors.shape, dtype=np.float32)\n","    gradOutsideVectors = np.zeros(outsideVectors.shape, dtype=np.float32)\n","\n","    ### YOUR CODE HERE\n","    centerWordIdx = word2Ind[currentCenterWord]\n","    centerWordVec = centerWordVectors[centerWordIdx]\n","\n","    for w in outsideWords:\n","        outsideWordIdx = word2Ind[w]\n","        l, gradCenter, gradOutside = word2vecLossAndGradient(\n","            centerWordVec, outsideWordIdx, outsideVectors, dataset)\n","        loss += l\n","        gradCenterVecs[centerWordIdx] += gradCenter\n","        gradOutsideVectors += gradOutside\n","    ### END YOUR CODE\n","\n","    return loss, gradCenterVecs, gradOutsideVectors\n","\n","#############################################\n","# Testing functions below. DO NOT MODIFY!   #\n","#############################################\n","\n","def word2vec_sgd_wrapper(word2vecModel, word2Ind, wordVectors, dataset,\n","                         windowSize,\n","                         word2vecLossAndGradient=naiveSoftmaxLossAndGradient):\n","    batchsize = 50\n","    loss = 0.0\n","    grad = np.zeros(wordVectors.shape)\n","    N = wordVectors.shape[0]\n","    centerWordVectors = wordVectors[:int(N/2),:]\n","    outsideVectors = wordVectors[int(N/2):,:]\n","    for i in range(batchsize):\n","        windowSize1 = random.randint(1, windowSize)\n","        centerWord, context = dataset.getRandomContext(windowSize1)\n","\n","        c, gin, gout = word2vecModel(\n","            centerWord, windowSize1, context, word2Ind, centerWordVectors,\n","            outsideVectors, dataset, word2vecLossAndGradient\n","        )\n","        loss += c / batchsize\n","        grad[:int(N/2), :] += gin / batchsize\n","        grad[int(N/2):, :] += gout / batchsize\n","\n","    return loss, grad"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3ATMPev9ZkbI","colab_type":"code","colab":{}},"source":["# Reset the random seed to make sure that everyone gets the same results\n","random.seed(314)\n","dataset = StanfordSentiment()\n","tokens = dataset.tokens()\n","nWords = len(tokens)\n","\n","# We are going to train 10-dimensional vectors for this assignment\n","dimVectors = 10\n","\n","# Context size\n","C = 5\n","\n","# Reset the random seed to make sure that everyone gets the same results\n","random.seed(31415)\n","np.random.seed(9265)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NxVDTYv0gd6I","colab_type":"code","colab":{}},"source":["# initialize word vectors\n","wordVectors = np.concatenate(\n","    ((np.random.rand(nWords, dimVectors) - 0.5) /\n","       dimVectors, np.zeros((nWords, dimVectors))),\n","    axis=0).astype(np.float32)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UjLzz6X4ZuLO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":748},"outputId":"cfb801a3-892d-42ae-c0cd-74b5717dae57","executionInfo":{"status":"ok","timestamp":1567852791871,"user_tz":-480,"elapsed":20290717,"user":{"displayName":"radream","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdVX7T48nM1swQqTFQB37YCJpipfpOuklEdcRHBQ=s64","userId":"01110408961739688657"}}},"source":["startTime=time.time()\n","wordVectors = sgd(\n","    lambda vec: word2vec_sgd_wrapper(skipgram, tokens, vec, dataset, C,\n","        negSamplingLossAndGradient),\n","    wordVectors, 0.3, 40000, None, True, PRINT_EVERY=1000)\n","# Note that normalization is not called here. This is not a bug,\n","# normalizing during training loses the notion of length.\n","\n","print(\"sanity check: cost at convergence should be around or below 10\")\n","print(\"training took %d seconds\" % (time.time() - startTime))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["iter 100: 0.008789\n","iter 1000: 0.008382\n","iter 2000: 0.007977\n","iter 3000: 0.007588\n","iter 4000: 0.007216\n","iter 5000: 0.006861\n","iter 6000: 0.006522\n","iter 7000: 0.006200\n","iter 8000: 0.005893\n","iter 9000: 0.005601\n","iter 10000: 0.005324\n","iter 11000: 0.005060\n","iter 12000: 0.004809\n","iter 13000: 0.004570\n","iter 14000: 0.004344\n","iter 15000: 0.004128\n","iter 16000: 0.003923\n","iter 17000: 0.003728\n","iter 18000: 0.003543\n","iter 19000: 0.003367\n","iter 20000: 0.003200\n","iter 21000: 0.003041\n","iter 22000: 0.002890\n","iter 23000: 0.002747\n","iter 24000: 0.002610\n","iter 25000: 0.002481\n","iter 26000: 0.002358\n","iter 27000: 0.002241\n","iter 28000: 0.002130\n","iter 29000: 0.002024\n","iter 30000: 0.001924\n","iter 31000: 0.001829\n","iter 32000: 0.001738\n","iter 33000: 0.001652\n","iter 34000: 0.001571\n","iter 35000: 0.001493\n","iter 36000: 0.001419\n","iter 37000: 0.001349\n","iter 38000: 0.001283\n","iter 39000: 0.001219\n","iter 40000: 0.001159\n","sanity check: cost at convergence should be around or below 10\n","training took 20289 seconds\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WsYpdtLmWtUF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"4ecc6883-33fc-433b-979f-e9739b932881","executionInfo":{"status":"ok","timestamp":1567853571816,"user_tz":-480,"elapsed":4526,"user":{"displayName":"radream","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdVX7T48nM1swQqTFQB37YCJpipfpOuklEdcRHBQ=s64","userId":"01110408961739688657"}}},"source":["! ls"],"execution_count":25,"outputs":[{"output_type":"stream","text":["__MACOSX\t\tsaved_params_35000.npy\t  saved_state_30000.pickle\n","sample_data\t\tsaved_params_40000.npy\t  saved_state_35000.pickle\n","saved_params_10000.npy\tsaved_params_5000.npy\t  saved_state_40000.pickle\n","saved_params_15000.npy\tsaved_state_10000.pickle  saved_state_5000.pickle\n","saved_params_20000.npy\tsaved_state_15000.pickle  stanfordSentimentTreebank\n","saved_params_25000.npy\tsaved_state_20000.pickle\n","saved_params_30000.npy\tsaved_state_25000.pickle\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EWo-s9dWZjPv","colab_type":"code","colab":{}},"source":["which_iter = 40000\n","params = np.load(\"saved_params_%d.npy\" % which_iter)\n","wordVectors = params"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WghocKMpomYZ","colab_type":"code","colab":{}},"source":["# concatenate the input and output word vectors\n","wordVectors = np.concatenate(\n","    (wordVectors[:nWords,:], wordVectors[nWords:,:]),\n","    axis=0)\n","\n","visualizeWords = [\n","    \"great\", \"cool\", \"brilliant\", \"wonderful\", \"well\", \"amazing\",\n","    \"worth\", \"sweet\", \"enjoyable\", \"boring\", \"bad\", \"dumb\",\n","    \"annoying\", \"female\", \"male\", \"queen\", \"king\", \"man\", \"woman\", \"rain\", \"snow\",\n","    \"hail\", \"coffee\", \"tea\"]\n","\n","visualizeIdx = [tokens[word] for word in visualizeWords]\n","visualizeVecs = wordVectors[visualizeIdx, :]\n","temp = (visualizeVecs - np.mean(visualizeVecs, axis=0))\n","covariance = 1.0 / len(visualizeIdx) * temp.T.dot(temp)\n","U,S,V = np.linalg.svd(covariance)\n","coord = temp.dot(U[:,0:2])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Aunqyry8bXny","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":390},"outputId":"a9ac78b8-0d27-479c-a037-5ca1cc739367","executionInfo":{"status":"ok","timestamp":1567854791011,"user_tz":-480,"elapsed":2090,"user":{"displayName":"radream","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCdVX7T48nM1swQqTFQB37YCJpipfpOuklEdcRHBQ=s64","userId":"01110408961739688657"}}},"source":["fig = plt.figure(figsize=(9,6))\n","ax = fig.add_subplot(111)\n","for i in range(len(visualizeWords)):\n","    ax.text(coord[i,0], coord[i,1], visualizeWords[i],\n","        bbox=dict(facecolor='green', alpha=0.1))\n","\n","ax.set_xlim((np.min(coord[:,0]), np.max(coord[:,0])))\n","ax.set_ylim((np.min(coord[:,1]), np.max(coord[:,1])))\n","ax.xaxis.label.set_color('w')\n","ax.yaxis.label.set_color('w')\n","ax.tick_params(axis='x', colors='w')\n","ax.tick_params(axis='y', colors='w')\n","ax.set_title('Word Embedding Space', color='w');"],"execution_count":45,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAlgAAAF1CAYAAAA0vJSpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n","text/plain":["<Figure size 648x432 with 1 Axes>"]},"metadata":{"tags":[]}}]}]}